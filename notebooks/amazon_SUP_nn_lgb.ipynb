{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "sys.path.append(\"../model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from io_utils import load_dataset, load_model, model_log\n",
    "from metric import performance_logloss, performance_acc\n",
    "\n",
    "from coordinate_ot_adaptation import adaptation\n",
    "from labelshift_correction import build_pivot_dataset, adjust_model\n",
    "from greedy_search import forward_greedy_search\n",
    "from train_utils import sample_validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"SUP\"\n",
    "source_version = \"opt\" # the version of embedding matrix & prediction model that we use\n",
    "\n",
    "task = \"amazon\"\n",
    "data_type = \"msda\"\n",
    "dim = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_selected_features = {\"lgb\":{}, \"nn\":{}}\n",
    "for seed in range(10):\n",
    "    for model_domain in [\"books\", \"dvd\", \"elec\", \"kitchen\"]:\n",
    "        for data_domain in [\"books\", \"dvd\", \"elec\", \"kitchen\"]:\n",
    "            if data_domain != model_domain:\n",
    "                torch.manual_seed(seed)\n",
    "                np.random.seed(seed)\n",
    "\n",
    "                source_train, source_train_label, source_test, source_test_label = load_dataset(\"../data/\", \n",
    "                                                                                        task, model_domain, data_type, dim)\n",
    "                target_train, target_train_label, target_test, target_test_label = load_dataset(\"../data/\", \n",
    "                                                                                        task, data_domain, data_type, dim)\n",
    "                \n",
    "                adapt = adaptation(cate_dim=0, num_dim=dim)\n",
    "                adapt.fit(target_train, source_train)\n",
    "                \n",
    "                target_train_trans = adapt.transform(target_train, repeat=1, njobs=20)\n",
    "\n",
    "                for model_type in [\"lgb\", \"nn\"]:\n",
    "                    num_selected_features[model_type].setdefault(model_domain, {})\n",
    "                    num_selected_features[model_type][model_domain].setdefault(data_domain, [])\n",
    "                    model = load_model(\"../model/\", task, model_domain, model_type, dim, source_version)\n",
    "                    \n",
    "                    params = {\n",
    "                        \"model\": model, \n",
    "                        \"valids\": [target_train, target_train_trans],\n",
    "                        \"valid_label\": target_train_label, \n",
    "                        \"repeat\": 1,\n",
    "                        \"performance\": performance_logloss,\n",
    "                        \"feature_cluster\":[[i] for i in range(target_train.shape[-1])],\n",
    "                        \"best\": None,\n",
    "                        \"feature_mask\": None,\n",
    "                        \"verbose\": False\n",
    "                    }\n",
    "\n",
    "                    # greedy feature selection\n",
    "                    feature_mask, evolution_perf, best_history = forward_greedy_search(**params)\n",
    "                    \n",
    "                    path = os.path.join(\"./results\", task, version, \n",
    "                                 \"{}_{}\".format(model_type, source_version), \n",
    "                                 model_domain, data_domain, \"exp{}\".format(seed))\n",
    "                    if not os.path.exists(path):\n",
    "                        os.makedirs(path)\n",
    "                        \n",
    "                    np.save(os.path.join(path, \"feature_mask\"), feature_mask)\n",
    "                    num_selected_features[model_type][model_domain][data_domain].append(feature_mask.sum())\n",
    "                    \n",
    "                    # target test transformation based on selected features\n",
    "                    target_test_trans = adapt.transform(target_test, repeat=1, interpolation=feature_mask, njobs=20)\n",
    "                    \n",
    "                    pred = model.predict(target_test_trans)\n",
    "                    np.save(os.path.join(path, \"target_test_pred\"), pred)\n",
    "                    \n",
    "                    perf = performance_logloss(pred, target_test_label)\n",
    "                    model_log(\"../logs/logloss/\", task, model_domain, model_type, dim, source_version, \n",
    "                             \"{};{}: {}\".format(version, data_domain, perf))\n",
    "                    print(\"Prediction logloss\", model_domain, data_domain, perf, flush=True)\n",
    "\n",
    "                    perf = performance_acc(pred, target_test_label)\n",
    "                    model_log(\"../logs/acc/\", task, model_domain, model_type, dim, source_version, \n",
    "                             \"{};{}: {}\".format(version, data_domain, perf))\n",
    "                    print(\"Prediction accuracy\", model_domain, data_domain, perf, flush=True)\n",
    "\n",
    "\n",
    "path = os.path.join(\"./results\", task, version)\n",
    "np.save(os.path.join(path, \"num_selected_features\"), num_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_domain in [\"books\", \"dvd\", \"elec\", \"kitchen\"]:\n",
    "    for data_domain in [\"books\", \"dvd\", \"elec\", \"kitchen\"]:\n",
    "        if model_domain != data_domain:\n",
    "            for model_type in [\"nn\", \"lgb\"]:\n",
    "                print(model_domain, data_domain, model_type, \"avg num features:\",\n",
    "                      np.mean(num_selected_features[model_type][model_domain][data_domain]))\n",
    "                print(model_domain, data_domain, model_type, \"std num features:\",\n",
    "                      np.std(num_selected_features[model_type][model_domain][data_domain]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
