{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "sys.path.append(\"../model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from mcd_model import mcd_model_num, fully_connected_nn\n",
    "from io_utils import load_dataset, load_model, model_log\n",
    "from metric import performance_logloss, performance_acc\n",
    "from train_utils import extend_dataset, reduce_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"mcd\"\n",
    "\n",
    "task = \"amazon\"\n",
    "data_type = \"msda\"\n",
    "\n",
    "\n",
    "dim = 400\n",
    "epoch = 50\n",
    "batch_size = 128\n",
    "version = \"opt\" # the version of embedding matrix & prediction model\n",
    "\n",
    "device = torch.device(\"cuda\") # device of training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_range = [0.0001, 0.0005, 0.001, 0.005]\n",
    "model_lr = {}\n",
    "for model_domain in [\"books\", \"dvd\", \"elec\", \"kitchen\"]:\n",
    "    model_lr[model_domain] = {}\n",
    "    for data_domain in [\"books\", \"dvd\", \"elec\", \"kitchen\"]:\n",
    "        if data_domain != model_domain:\n",
    "            perfs_lr = []\n",
    "            for lr in lr_range:\n",
    "                perfs = []\n",
    "                for seed in range(10):\n",
    "                    torch.manual_seed(seed)\n",
    "                    np.random.seed(seed)\n",
    "\n",
    "                    # Load dataset\n",
    "                    source_train, source_train_label, source_test, source_test_label = load_dataset(\"../data/\", \n",
    "                                                                                            task, model_domain, data_type, dim)\n",
    "                    target_train, target_train_label, target_test, target_test_label = load_dataset(\"../data/\", \n",
    "                                                                                            task, data_domain, data_type, dim)\n",
    "\n",
    "                    # Split train valid data\n",
    "                    source_train, source_valid, source_train_label, source_valid_label = train_test_split(\n",
    "                        source_train, source_train_label, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "                    # init model & train\n",
    "                    dnn = fully_connected_nn(dim)\n",
    "                    model = mcd_model_num(dnn, device)\n",
    "\n",
    "                    source_index, target_index = reduce_dataset(source_train, target_train)\n",
    "\n",
    "                    model.fit(source_train[source_index], source_train_label[source_index], \n",
    "                              target_train[target_index],\n",
    "                              source_valid, source_valid_label, \n",
    "                              epoch=epoch, batch_size=batch_size, lr=lr,\n",
    "                              early_stop=False, verbose=False)\n",
    "\n",
    "                    # predict on source test\n",
    "                    pred = model.predict(source_test)\n",
    "                    perf = performance_logloss(pred, source_test_label)\n",
    "                    perfs.append(perf)\n",
    "                perfs_lr.append(np.mean(perfs))\n",
    "            model_lr[model_domain][data_domain] = lr_range[np.argmax(perfs_lr)]\n",
    "            \n",
    "path = os.path.join(\"./results\", task, model_type, \n",
    "                     \"{}_{}\".format(model_type, version))\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "np.save(os.path.join(path, \"model_lr\"), model_lr)\n",
    "\n",
    "print(\"Optimal lr for each period:\", model_lr, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(10):\n",
    "    for model_domain in [\"books\", \"dvd\", \"elec\", \"kitchen\"]:\n",
    "        for data_domain in [\"books\", \"dvd\", \"elec\", \"kitchen\"]:\n",
    "            if data_domain != model_domain:\n",
    "                torch.manual_seed(seed)\n",
    "                np.random.seed(seed)\n",
    "\n",
    "                # Load dataset\n",
    "                source_train, source_train_label, source_test, source_test_label = load_dataset(\"../data/\", \n",
    "                                                                                        task, model_domain, data_type, dim)\n",
    "                target_train, target_train_label, target_test, target_test_label = load_dataset(\"../data/\", \n",
    "                                                                                        task, data_domain, data_type, dim)\n",
    "\n",
    "                # Split train valid data\n",
    "                source_train, source_valid, source_train_label, source_valid_label = train_test_split(\n",
    "                    source_train, source_train_label, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "                # init model & train\n",
    "                dnn = fully_connected_nn(dim)\n",
    "                model = mcd_model_num(dnn, device)\n",
    "\n",
    "                source_index, target_index = reduce_dataset(source_train, target_train)\n",
    "\n",
    "                model.fit(source_train[source_index], source_train_label[source_index], \n",
    "                          target_train[target_index],\n",
    "                          source_valid, source_valid_label, \n",
    "                          epoch=epoch, batch_size=batch_size, lr=model_lr[model_domain][data_domain],\n",
    "                          early_stop=False, verbose=False)\n",
    "\n",
    "                # prediction and save log\n",
    "                path = os.path.join(\"./results\", task, model_type, \n",
    "                             \"{}_{}\".format(model_type, version), \n",
    "                             model_domain, data_domain, \"exp{}\".format(seed))\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "\n",
    "                # Source prediction\n",
    "                pred = model.predict(source_test)\n",
    "                np.save(os.path.join(path, \"source_test_pred\"), pred.astype(np.float16))\n",
    "\n",
    "                perf = performance_logloss(pred, source_test_label)\n",
    "                model_log(\"../logs/logloss/\", task, model_domain, \"nn\", dim, version, \n",
    "                         \"{};source_{}: {}\".format(model_type, data_domain, perf))\n",
    "                print(\"Source Prediction logloss\", model_domain, data_domain, perf, flush=True)\n",
    "\n",
    "                perf = performance_acc(pred, source_test_label)\n",
    "                model_log(\"../logs/acc/\", task, model_domain, \"nn\", dim, version, \n",
    "                         \"{};source_{}: {}\".format(model_type, data_domain, perf))\n",
    "                print(\"Source Prediction accuracy\", model_domain, data_domain, perf, flush=True)\n",
    "                \n",
    "                # Traget prediction\n",
    "                pred = model.predict(target_test)\n",
    "                np.save(os.path.join(path, \"target_test_pred\"), pred.astype(np.float16))\n",
    "\n",
    "                perf = performance_logloss(pred, target_test_label)\n",
    "                model_log(\"../logs/logloss/\", task, model_domain, \"nn\", dim, version, \n",
    "                         \"{};target_{}: {}\".format(model_type, data_domain, perf))\n",
    "                print(\"Target Prediction logloss\", model_domain, data_domain, perf, flush=True)\n",
    "\n",
    "                perf = performance_acc(pred, target_test_label)\n",
    "                model_log(\"../logs/acc/\", task, model_domain, \"nn\", dim, version, \n",
    "                         \"{};target_{}: {}\".format(model_type, data_domain, perf))\n",
    "                print(\"Target Prediction accuracy\", model_domain, data_domain, perf, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
